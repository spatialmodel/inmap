/**
 * @generated
 */
module.exports = [
  {
    "path": "2022/12/15/tutorial.html",
    "content": "\nThis tutorial provides you a simple access to the source-receptor matrices using AWS and Python. After installing all the dependencies, you can easily follow the instructions to work with the SR matrices.\n\n<!--truncate-->\n\n## Introduction\n\nSource-receptor (SR) matrices can allow users to get results similar to those that would be produced by running an air quality model simulation, but without having to actually run an air quality model simulation. In this tutorial, we will learn how to work with the SR matrices described in these two papers:\n\n* Jinhyok Heo, Peter J. Adams, H. Gao (2017) Public Health Costs Accounting of Inorganic PM<sub>2.5</sub> Pollution in Metropolitan Areas of the United States Using a Risk-Based Source-Receptor Model, <i>Environment International</i>, 106, 119â€“126. ([link](https://barney.ce.cmu.edu/~jinhyok/apsca/))\n\n* Andrew L. Goodkind, Christopher W. Tessum, Jay S. Coggins, Jason D. Hill, Julian D. Marshall (2019) Fine-scale damage estimates of particulate matter air pollution reveal opportunities for location-specific mitigation of emissions. <i>Proceedings of the National Academy of Sciences</i>. ([link](https://www.pnas.org/content/early/2019/04/02/1816102116.short))\n\nWe will refer to the SR matrix from the first paper as APSCA, and the one from the second paper as ISRM.\n\nAlthough SR matrices are typically easier to use than full air quality models, they are often made up of files that can be hundreds of gigabytes in size, and it can be complicated to get estimates of emissions into the correct format to use with the SR matrix.\nWe have developed some tools to get around these limitations: the website https://inmap.run hosts the SR matrices described in the two papers above and provides functionality for taking emissions in [shapefile](https://doc.arcgis.com/en/arcgis-online/reference/shapefiles.htm) format, running them through an SR matrix, and returning the result as a shapefile.\nAdditionally, the [`inmap cloud`](https://inmap.run/docs/cmd/inmap_cloud/) command-line tool allows users to interact with the https://inmap.run website.\n\nBecause not all users may be comfortable using command-line tools or shapefiles, we will demonstrate here how to use the [GeoPandas](http://geopandas.org/) library in the [Python](https://www.python.org/) scripting and programming language to interact with https://inmap.run, which will hopefully provide an additional level of convenience.\n\nIf you prefer, a working [Jupyter notebook](https://jupyter.org/) version of this tutorial is available [here](https://github.com/xiaor2/inmap/tree/master/website/static/blog/2022-12-15-tutorial/sr_example.ipynb).\n\n## Set up environment\n\nThe code below is some boilerplate to make this work with either Python version 2 or 3.\n\n\n```python\nfrom __future__ import (absolute_import, division,\n                        print_function, unicode_literals)\nfrom builtins import *\n```\n\n## Prepare emissions\n\nFor this example, we are going to estimate the air pollution-related health impacts of electricity generation in the United States.\nTo do this we will start with emissions data from the US EPA's [National Emissions Inventory](https://www.epa.gov/air-emissions-modeling/emissions-modeling-platforms) for [year 2016](https://www.epa.gov/air-emissions-modeling/2016-alpha-platform).\n\nThe tools at https://inmap.run require input data containing:\n* information on the location of the emissions source (required, in the form of either a point, line, or polygon geometry with a [spatial reference](https://en.wikipedia.org/wiki/Spatial_reference_system) specified), \n* amounts of emissions (optional, allowed emission types are VOC, NOx, NH3, SOx, and PM2_5; units must be either short tons per year, kilograms per year, or micrograms per second), and\n* (smoke) stack parameters relevant to plume rise, which is how high up the emissions go immediately after they are released (optional; allowed parameters are \"height\", \"diam\", \"temp\", and \"velocity\" in units of m, m, K, and m/s, respectively).\n\nThe NEI data we are downloading includes, among other things, all of the information above. More information about the file format is available [here](https://www.cmascenter.org/smoke/documentation/4.5/html/ch08s02s08.html#sect_input_ptinv_ff10).\n\nAlthough there are a number of ways to process spatial data using Python, for this exercise we will use the [GeoPandas](http://geopandas.org/) library. Instructions for installing GeoPandas are [here](http://geopandas.org/install.html).\n\nThe code below downloads the emissions data from the EPA and converts it into a GeoPandas dataframe. Keep in mind that if you have a different type of emissions data that you want to use, you may want to use a different method for importing it.\nIn general, the tools we work with here are for estimating the concentration and health impacts of pollutant emissions, not for estimating the emissions themselves.\n\n\n```python\n# Note: This step can take a while to run.\n\nfrom io import BytesIO, TextIOWrapper\nfrom zipfile import ZipFile\nimport urllib.request\nimport csv\nfrom shapely.geometry import Point\nimport geopandas as gpd\n\n# Download file from EPA website.\nurl = urllib.request.urlopen(\"ftp://newftp.epa.gov/air/emismod/2016/alpha/2016fd/emissions/2016fd_inputs_point.zip\")\n\nVOC, NOx, NH3, SOx, PM2_5 = [], [], [], [], []\nheight, diam, temp, velocity = [], [], [],  []\ncoords = []\n\ndef add_record(row):\n    \"\"\" Process one row of the emissions file \"\"\"\n    pol = row[12] # The pollutant is in the 13th column of the CSV file\n                  # (In Python, the first column is called column 0.)\n    emis = row[13] # We are only extracting annual total emissions here. \n                   # If monthly emissions are reported, we'll miss them.\n                   # Emissions are short tons/year.\n    if emis == '': return\n    if pol in ['VOC', 'VOC_INV', 'XYL', 'TOL', 'TERP', 'PAR', 'OLE', 'NVOL', 'MEOH', \n               'ISOP', 'IOLE', 'FORM', 'ETOH', 'ETHA', 'ETH', 'ALD2', 'ALDX', 'CB05_ALD2', \n               'CB05_ALDX', 'CB05_BENZENE', 'CB05_ETH', 'CB05_ETHA', 'CB05_ETOH', \n               'CB05_FORM', 'CB05_IOLE', 'CB05_ISOP', 'CB05_MEOH', 'CB05_OLE', 'CB05_PAR', \n               'CB05_TERP', 'CB05_TOL', 'CB05_XYL', 'ETHANOL', 'NHTOG', 'NMOG', 'VOC_INV']:\n        VOC.append(float(emis))\n        NOx.append(0)\n        NH3.append(0)\n        SOx.append(0)\n        PM2_5.append(0)\n    elif pol in ['PM25-PRI', 'PM2_5', 'DIESEL-PM25', 'PAL', 'PCA', 'PCL', 'PEC', 'PFE', 'PK', \n                'PMG', 'PMN', 'PMOTHR', 'PNH4', 'PNO3', 'POC', 'PSI', 'PSO4', 'PTI']:\n        VOC.append(0)\n        NOx.append(0)\n        NH3.append(0)\n        SOx.append(0)\n        PM2_5.append(float(emis))\n    elif pol in ['NOX', 'HONO', 'NO', 'NO2']:\n        VOC.append(0)\n        NOx.append(float(emis))\n        NH3.append(0)\n        SOx.append(0)\n        PM2_5.append(0)\n    elif pol == 'NH3':\n        VOC.append(0)\n        NOx.append(0)\n        NH3.append(float(emis))\n        SOx.append(0)\n        PM2_5.append(0)\n    elif pol == 'SO2':\n        VOC.append(0)\n        NOx.append(0)\n        NH3.append(0)\n        SOx.append(float(emis))\n        PM2_5.append(0)\n    else: return\n    \n    h = row[17]\n    height.append(float(h) * 0.3048) if h != '' else height.append(0)\n    \n    d = row[18]\n    diam.append(float(d) * 0.3048) if d != '' else diam.append(0)\n\n    t = row[19]\n    temp.append((float(t) - 32) * 5.0/9.0 + 273.15) if t != '' else temp.append(0)\n        \n    v = row[21]\n    velocity.append(float(v) * 0.3048) if v != '' else velocity.append(0)\n    \n    coords.append(Point(float(row[23]), float(row[24])))\n\nwith ZipFile(BytesIO(url.read())) as zf:\n    for contained_file in zf.namelist():\n        if \"egu\" in contained_file: # Only process files with electricity generating unit (EGU) emissions.\n            for row in csv.reader(TextIOWrapper(zf.open(contained_file, 'r'), newline='')):\n                if (len(row) == 0) or (len(row[0]) == 0) or (row[0][0] == '#'): continue\n                add_record(row)\n\nemis = gpd.GeoDataFrame({\n    \"VOC\": VOC, \"NOx\": NOx, \"NH3\": NH3, \"SOx\": SOx, \"PM2_5\": PM2_5,\n    \"height\": height, \"diam\": diam, \"temp\": temp, \"velocity\": velocity,\n}, geometry=coords, crs={'init': 'epsg:4269'})\n```\n\nNow, let's inspect our emissions to ensure they look resonable.\n\n\n```python\n# First, we print the first several rows of the dataframe:\nemis.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VOC</th>\n      <th>NOx</th>\n      <th>NH3</th>\n      <th>SOx</th>\n      <th>PM2_5</th>\n      <th>height</th>\n      <th>diam</th>\n      <th>temp</th>\n      <th>velocity</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.57383 32.38166)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.57382 32.38199)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.57385 32.38032)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.57384 32.38065)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.57384 32.38065)</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n# Now, let's look at the sums of emissions for all power plants (in short tons/year).\nemis.sum(axis=0)[[\"VOC\", \"NOx\", \"NH3\", \"SOx\", \"PM2_5\"]]\n```\n\n    VOC      3.345280e+04\n    NOx      1.314463e+06\n    NH3      2.501248e+04\n    SOx      1.571217e+06\n    PM2_5    1.408227e+05\n    dtype: float64\n\n\n\n\n```python\n# Finally, lets make some maps of the emissions.\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npols = [\"SOx\", \"NOx\", \"PM2_5\", \"VOC\", \"NH3\"]\npol_names = [\"SO$_2$\", \"NO$_x$\", \"PM$_{2.5}$\", \"VOC\", \"NH$_3$\"]\n\nfig, axes = plt.subplots(figsize=(7, 3), nrows=2, ncols=3, sharex=True, sharey=True)\nplt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.1, hspace=0.1)\n\ni = 0\nfor x in axes:\n    for ax in x:\n        if i < len(pols):\n            emis.plot(ax=ax, markersize=emis[pols[i]]**0.5 / 5)\n            ax.set_title(pol_names[i])\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.axis('off')\n        i = i+1\nplt.show()\n```\n\n\n    \n![png](/blog/2022-12-15-tutorial/output_7_0.png)\n    \n\n\nFig. 1: US year-2016 electricity generators. Areas of dots are proportionate to rate of emissions of each pollutant.\n\nThese maps could be improved by adding politcal boundaries, etc. We will leave that as an exercise for the reader.\n\nAlternatively to the steps above, if you already have a shapefile of the correct format saved locally, you could read it in using:\n\n```python\nimport geopandas as gpd\nemis = gpd.read_file(\"/path/to/file.shp\")\n```\n\n## Use SR matrices to estimate concentrations and health impacts\n\nOnce we have our emissions in GeoPandas format, we are ready to run them through our SR matrices.\nTo do this, we will use the `run_sr` function in the `sr_util.py` script that we have created for this purpose. You can view `sr_util.py` [here](https://github.com/spatialmodel/inmap/blob/master/website/static/blog/2019-04-20-sr/sr_util.py), and if you want to run the code here you will need to download the file into the directory you are working in.\n\nThe `run_sr` function takes several arguments, which we will describe here.\n\n* `emis`: A geopandas dataframe of emissions, like the one we've prepared here.\n\n* `model`: Which SR matrix to use. Currently the ISRM (Goodkind et al. paper above) and APSCA (Heo et al. paper above) models are available. The options for this argument are:\n    * `isrm`: The InMAP SR matrix\n    * `apsca_q0`: The APSCA SR matrix, annual average\n    * `apsca_q1`: The APSCA SR matrix, Jan-Mar season\n    * `apsca_q2`: The APSCA SR matrix, Apr-Jun season\n    * `apsca_q3`: The APSCA SR matrix, Jul-Sep season\n    * `apsca_q4`: The APSCA SR matrix, Oct-Dec season\n    \n* `emis_units`: The units that the emissions are in. Allowed values: `tons/year`, `kg/year`, `ug/s`, and `Î¼g/s`. We will use tons/year, because those are the units our data are in.\n\n* `output_variables`: The information we want the model to output, input as a dictionary in the form {\"variable_name\": \"formula\"}. Refer [here](https://inmap.run/docs/results/) for more information regarding formulas. The native model variables available in the SR matrices for use in output formulas are:\n    * `PrimaryPM25`: Calculated primary PM<sub>2.5</sub> concentration (Î¼g/mÂ³)\n    * `pNH4`: Calculated particulate NH<sub>4</sub> concentration (Î¼g/mÂ³)\n    * `pSO4`: Calculated particulate SO<sub>4</sub> concentration (Î¼g/mÂ³)\n    * `pNO3`: Calculated particulate NO</sub>3</sub> concentration (Î¼g/mÂ³)\n    * `SOA`: Calculated secondary organic aerosol concentration (Î¼g/mÂ³)\n    * `Asian`: Year 2010 Asian Population (people/grid cell)\n    * `Black`: Year 2010 Black Population (people/grid cell)\n    * `Latino`: Year 2010 Latino Population (people/grid cell)\n    * `Native`: Year 2010 Native Population (people/grid cell)\n    * `TotalPop`: Year 2010 total Population (people/grid cell)\n    * `WhiteNoLat`: Year 2010 White non-Latino Population (people/grid cell)\n    * `MortalityRate`: Year 2005 baseline overall population mortality rate (deaths per year per 100,000 people)\n    * `Baseline NH3`: Baseline NH3 Concentration (Î¼g/mÂ³)\n    * `Baseline NOx`: Baseline NOx Concentration (Î¼g/mÂ³)\n    * `Baseline SOA`: Baseline SOA Concentration (Î¼g/mÂ³)\n    * `Baseline SOx`: Baseline SOx Concentration (Î¼g/mÂ³)\n    * `Baseline TotalPM25`: Baseline TotalPM25 Concentration (Î¼g/mÂ³)\n    * `Baseline VOC`: Baseline VOC Concentration (Î¼g/mÂ³)\n    * `Baseline pNH4`: Baseline pNH4 Concentration (Î¼g/mÂ³)\n    * `Baseline pNO3`: Baseline pNO3 Concentration (Î¼g/mÂ³)\n    * `Baseline pSO4`: Baseline pSO4 Concentration (Î¼g/mÂ³)\n    * `Asian`: Year 2010 Asian Population (people/grid cell)\n    * `Black`: Year 2010 Black Population (people/grid cell)\n    * `Latino`: Year 2010 Latino Population (people/grid cell)\n    * `Native`: Year 2010 Native Population (people/grid cell)\n    * `TotalPop`: Year 2010 total Population (people/grid cell)\n    * `WhiteNoLat`: Year 2010 White non-Latino Population (people/grid cell)\n    * `UAvg`: Average East-West wind speed (m/s)\n    * `VAvg`: Average North-South wind speed (m/s)\n    * `WAvg`: Average up-down wind speed (m/s)\n    * `UDeviation`: Average deviation from East-West velocity (m/s)\n    * `VDeviation`: Average deviation from North-South velocity (m/s)\n    * `AOrgPartitioning`: Organic particle partitioning (-)\n    * `SPartitioning`: Sulfur particle partitioning (-)\n    * `NOPartitioning`: Nitrate particle partitioning (-)\n    * `NHPartitioning`: Ammonium particle partitioning (-)\n    * `SO2oxidation`: SO2 oxidation to SO4 by HO and H2O2 (1/s)\n    * `ParticleWetDep`: Particle wet deposition (1/s)\n    * `SO2WetDep`: SO2 wet deposition (1/s)\n    * `OtherGasWetDep`: Wet deposition: other gases (1/s)\n    * `ParticleDryDep`: Particle dry deposition (m/s)\n    * `NH3DryDep`: Ammonia dry deposition (m/s)\n    * `SO2DryDep`: SO2 dry deposition (m/s)\n    * `VOCDryDep`: VOC dry deposition (m/s)\n    * `NOxDryDep`: NOx dry deposition (m/s)\n    * `Kzz`: Grid center vertical diffusivity after applying convective fraction (mÂ²/s)\n    * `Kxxyy`: Grid center horizontal diffusivity (mÂ²/s)\n    * `M2u`: ACM2 upward mixing (Pleim 2007)  (1/s)\n    * `M2d`: ACM2 downward mixing (Pleim 2007) (1/s)\n    * `Dx`: Cell x length (m)\n    * `Dy`: Cell y length (m)\n    * `Dz`: Cell z length (m)\n    * `Volume`: Cell volume (mÂ³)\n    * `Temperature`: Average temperature (K)\n    * `WindSpeed`: RMS wind speed (m/s)\n    * `WindSpeedInverse`: RMS wind speed inverse (s/m)\n    * `WindSpeedMinusThird`: RMS wind speed^(-1/3)\n    * `WindSpeedMinusOnePointFour`: RMS wind speed^(-1.4)\n    * `S1`: Stability parameter (?)\n    * `SClass`: Stability class (0=Unstable; 1=Stable)\n    * `N`: N grid cell edge (m)\n    * `S`: S grid cell edge (m)\n    * `E`: E grid cell edge (m)\n    * `W`: W grid cell edge (m)\n\nYou can probably see that there are an infinite number of output variables that could be calculated. For this example, we will output three variables:\n\n1. `TotalPM25 = PrimaryPM25 + pNH4 + pSO4 + pNO3 + SOA`: In this equation, we are summing up all the different types of PM<sub>2.5</sub> that the model calculates to get total PM<sub>2.5</sub>.\n\n2. `deathsK = (exp(log(1.06)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate / 100000 * 1.025229357798165` In this equation, we are using the total PM<sub>2.5</sub> value we calculated above in a [Cox proportional hazards](https://en.wikipedia.org/wiki/Proportional_hazards_model) equation, along with information on population counts (`TotalPop`) and baseline mortality rates (`MortalityRate / 100000`) to calculate the number of deaths.\n    * 1.0465819687408728 is the ratio between year-2016 population (what we want) and year-2010 population (what the model has).\n    * 1.025229357798165 is the ratio between year-2016 mortality rate (what we want) and year-2005 mortality rate (what the model has).\n    * The value 1.06 represents an assumption that overall mortality rate increases by 6% for every 10 Î¼g/mÂ³ increase in PM<sub>2.5</sub> concentration, which is taken from [this](https://www.healtheffects.org/publication/extended-follow-and-spatial-analysis-american-cancer-society-study-linking-particulate) paper.\n    * The variable name, `deathsK`, comes from the fact that we're calculating deaths and that the 1.06 value comes from a report authored by Krewski et al.\n\n3. `deathsL = (exp(log(1.14)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate * 1.025229357798165 / 100000`: This is the same equation as the previous one, except we assume a 14% increase in morality rate for every 10 Î¼g/mÂ³ increase in PM<sub>2.5</sub> concentration, as [reported by LePeule et al](https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.1104660).\n\n\n```python\n# Below are the helper functions for the run_sr function\nimport time\nimport numpy as np\nimport zarr\nfrom shapely.geometry import Polygon, Point\nimport pandas as pd\nimport geopandas as gpd\nimport s3fs\n\ndef rect(i, w, s, e, n):\n    x = [w[i], e[i], e[i], w[i], w[i]]\n    y = [s[i], s[i], n[i], n[i], s[i]]\n    return x, y\n\ndef poly(sr):\n    ret = []\n    w = sr[\"W\"][:]\n    s = sr[\"S\"][:]\n    e = sr[\"E\"][:]\n    n = sr[\"N\"][:]\n    for i in range(52411):\n        x, y = rect(i, w, s, e, n)\n        ret.append(Polygon([[x[0],y[0]],[x[1],y[1]],[x[2],y[2]],\n                            [x[3],y[3]],[x[4],y[4]]]))\n    return ret\n```\n\nWe provide two ways to access the SR matrix:\n1. directly from the amazon s3\n    * If you choose this option, you can directly run the following codes.\n2. from local files (unavailble for now)\n    * You will need to download the file [here](https://zenodo.org/record/3590127#.Y6Jb_9XMIdV) first and put it in the same folder as this notebook.\n    * Then you can comment the url, fs and sr lines.\n    * Uncomment this line: sr = zarr.open(\"isrm_v1.2.1.zarr\", mode=\"r\")\n\n\n```python\n# define the run_sr function\ndef run_sr(emis, model, emis_units=\"tons/year\"):\n    start = time.time()\n    url = 's3://inmap-model/isrm_v1.2.1.zarr/'\n    fs = s3fs.S3FileSystem(anon=True, client_kwargs=dict(region_name='us-east-2'))\n    sr = zarr.open(s3fs.S3Map(url, s3=fs, check=False), mode=\"r\")\n#     the following line is used when we access the SR matrix from local files\n#     sr = zarr.open(\"isrm_v1.2.1.zarr\", mode=\"r\")\n\n    # build the geometry\n    p = poly(sr)\n    print(\"Making polygons as geometry.\")\n\n    # took the emis geopandas dataframe\n    df = pd.DataFrame({'Location': range(52411)})\n    gdf = gpd.GeoDataFrame(df, geometry=p)\n\n    # join the emis dataframe into the grid dataframe\n    emis.crs = \"+proj=longlat\"\n    gdf.crs = \"+proj=lcc +lat_1=33.000000 +lat_2=45.000000 +lat_0=40.000000 +lon_0=-97.000000 +x_0=0 +y_0=0 +a=6370997.000000 +b=6370997.000000 +to_meter=1\"\n    emis = emis.to_crs(gdf.crs)\n    join_right_df = gdf.sjoin(emis, how=\"right\")\n    print(\"Finished joining the dataframes.\")\n    \n    index = join_right_df.Location.tolist()\n\n    ppl = np.unique(join_right_df.Location.tolist())\n\n    num = range(0,len(ppl))\n\n    dictionary = dict(zip(ppl, num))\n        \n    SOA = sr['SOA'].get_orthogonal_selection(([0], ppl, slice(None)))\n    print(\"SOA data is allocated.\")\n    pNO3 = sr['pNO3'].get_orthogonal_selection(([0], ppl, slice(None)))\n    print(\"pNO3 data is allocated.\")\n    pNH4 = sr['pNH4'].get_orthogonal_selection(([0], ppl, slice(None)))\n    print(\"pNH4 data is allocated.\")\n    pSO4 = sr['pSO4'].get_orthogonal_selection(([0], ppl, slice(None)))\n    print(\"pSO4 data is allocated.\")\n    PM25 = sr['PrimaryPM25'].get_orthogonal_selection(([0], ppl, slice(None)))\n    print(\"PrimaryPM25 data is allocated.\")\n    \n    SOA_data, pNO3_data, pNH4_data, pSO4_data, PM25_data = 0.0, 0.0, 0.0, 0.0, 0.0\n    for i in range(len(index)):\n        SOA_data += SOA[0, dictionary[index[i]], :]*emis.VOC[i]\n        pNO3_data += pNO3[0, dictionary[index[i]], :]*emis.NOx[i]\n        pNH4_data += pNH4[0, dictionary[index[i]], :]*emis.NH3[i]\n        pSO4_data += pSO4[0, dictionary[index[i]], :]*emis.SOx[i]\n        PM25_data += PM25[0, dictionary[index[i]], :]*emis.PM2_5[i]\n    data = SOA_data + pNO3_data + pNH4_data + pSO4_data + PM25_data\n\n    print(\"Accessing the data.\")\n    if emis_units==\"tons/year\":\n        fact = 28766.639\n\n    TotalPM25 = fact * data\n    TotalPop = sr['TotalPop'][0:52411]\n    MortalityRate = sr['MortalityRate'][0:52411]\n    deathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate / 100000 * 1.025229357798165\n    deathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate / 100000 * 1.025229357798165\n    \n    ret = gpd.GeoDataFrame(pd.DataFrame({'SOA': fact * SOA_data,\n                                         'pNO3': fact * pNO3_data,\n                                         'pNH4': fact * pNH4_data,\n                                         'pSO4': fact * pSO4_data,\n                                         'PrimaryPM25': fact * PM25_data,\n                                         'TotalPM25': TotalPM25,\n                                         'deathsK': deathsK,\n                                         'deathsL': deathsL}), geometry=p[0:52411])\n\n    print(\"Finished (%.0f seconds)               \"%(time.time()-start))\n    return ret\n```\n\n\n```python\n# This step might take a while. (20-25 mins in the author's computer)\n# If this step is interrupted due to insufficient memory, you can try virtual memory.\nresultsISRM = run_sr(emis, model=\"isrm\", emis_units=\"tons/year\")\n```\n\n    Making polygons as geometry.\n    Finished joining the dataframes.\n    SOA data is allocated.\n    pNO3 data is allocated.\n    pNH4 data is allocated.\n    pSO4 data is allocated.\n    PrimaryPM25 data is allocated.\n    Accessing the data.\n    Finished (1401 seconds)               \n    \n\n\n```python\nresultsISRM.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SOA</th>\n      <th>pNO3</th>\n      <th>pNH4</th>\n      <th>pSO4</th>\n      <th>PrimaryPM25</th>\n      <th>TotalPM25</th>\n      <th>deathsK</th>\n      <th>deathsL</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000005</td>\n      <td>0.000033</td>\n      <td>0.000053</td>\n      <td>0.000062</td>\n      <td>0.000029</td>\n      <td>0.000182</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>POLYGON ((-2736000.000 -2088000.000, -2688000....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000005</td>\n      <td>0.000033</td>\n      <td>0.000053</td>\n      <td>0.000062</td>\n      <td>0.000029</td>\n      <td>0.000182</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>POLYGON ((-2736000.000 -2040000.000, -2688000....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000005</td>\n      <td>0.000033</td>\n      <td>0.000053</td>\n      <td>0.000062</td>\n      <td>0.000029</td>\n      <td>0.000182</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>POLYGON ((-2736000.000 -1992000.000, -2688000....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000005</td>\n      <td>0.000033</td>\n      <td>0.000053</td>\n      <td>0.000062</td>\n      <td>0.000029</td>\n      <td>0.000182</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>POLYGON ((-2736000.000 -1944000.000, -2688000....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000005</td>\n      <td>0.000033</td>\n      <td>0.000053</td>\n      <td>0.000062</td>\n      <td>0.000029</td>\n      <td>0.000182</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>POLYGON ((-2736000.000 -1896000.000, -2688000....</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n## Summarizing results\n\nNow that we have our results, the first thing we can do is sum up the number of deaths we are calculating:\n\n\n```python\ndeaths = pd.DataFrame.from_dict({\n    \"Model\": [\"ISRM\"],\n    \"Krewski Deaths\": [resultsISRM.deathsK.sum()],\n    \"LePeule Deaths\": [resultsISRM.deathsL.sum()],\n})\n\ndeaths\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Krewski Deaths</th>\n      <th>LePeule Deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISRM</td>\n      <td>7524.844164</td>\n      <td>16979.44742</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nWe're calculating somewhere between 7,500 and 17,000 deaths every year caused by air pollution emissions from electricity generators. \n\nWe can also estimate equivalent economic damages using a metric called Value of a Statistical Life, which we will take to be $9 million.\n\n\n```python\nvsl = 9.0e6\n\npd.DataFrame.from_dict({\n    \"Model\": [\"ISRM\"],\n    \"Krewski Damages\": deaths[\"Krewski Deaths\"] * vsl,\n    \"LePeule Damages\": deaths[\"LePeule Deaths\"] * vsl,\n})\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Krewski Damages</th>\n      <th>LePeule Damages</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISRM</td>\n      <td>6.772360e+10</td>\n      <td>1.528150e+11</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nSo the health damages from power plants are equivalent to between 67 and 152 billion dollars per year. By using multiple SR matrices and multiple esitimates of the relationship between concentrations and mortality rate, we're able to estimate the uncertainty in our results.\n\nThe final thing we'll do here is to make maps of our concentration results:\n\n\n```python\ncut = resultsISRM.TotalPM25.quantile(0.985)\nresultsISRM.plot(column=resultsISRM.TotalPM25, cmap=\"GnBu\", legend=True, \n                 vmin=0, vmax=cut, figsize=(6, 3))\n```\n\n\n\n\n    <AxesSubplot:>\n\n\n\n\n    \n![png](/blog/2022-12-15-tutorial/output_19_1.png)\n    \n\n\nFig. 2: PM<sub>2.5</sub> concentrations caused by electricity generation in the US.\n\nAs above, the maps would be better if political boundaries were added for reference, but we will leave that as homework, as there are other tutorials out there that describe how to do that.\n\nTo save out the results as a shapefile, use the following command:\n\n```python\nresultsISRM.to_file(\"output.shp\")\n```\n\nShapefiles can be opened in a GIS tool like [QGIS](https://qgis.org/) for further postprocessing if desired.\n\n## Conclusion\n\nHopefully this tutorial has given you the information you need to do your own air pollution analyses using SR matrices. If not, you can browse the documentation at https://inmap.run or contact the InMAP users group at https://groups.google.com/forum/#!forum/inmap-users.\n\n## Bonus! Visualization\nBelow is the total PM<sub>2.5</sub> concentration map.\n\n\n```python\nimport h3pandas\nimport pydeck as pdk\nimport json\n\n# Note that you can only run this chunck of codes once, because this will change the resultsISRM.\nresultsISRM.crs = \"+proj=lcc +lat_1=33.000000 +lat_2=45.000000 +lat_0=40.000000 +lon_0=-97.000000 +x_0=0 +y_0=0 +a=6370997.000000 +b=6370997.000000 +to_meter=1\"\nresultsISRM = resultsISRM.to_crs(\"+proj=longlat\")\n```\n\n\n```python\ngeolist = resultsISRM[[\"TotalPM25\",\"geometry\"]]\nres = geolist.h3.polyfill(5)\nmy_data = res.rename(columns ={'h3_polyfill':'hexIds'})[['TotalPM25','hexIds']]\n```\n\n\n```python\n# Define a layer to display on a map\nlayer = pdk.Layer(\n    \"H3ClusterLayer\",\n    my_data,\n    pickable=True,\n    stroked=True,\n    filled=True,\n    extruded=False,\n    get_hexagons=\"hexIds\",\n    get_fill_color=\"[255, TotalPM25 / 1.5 * 255, 0, 100]\",\n    get_line_color=[255, 255, 255],\n    line_width_min_pixels=0,\n)\n\n# Set the viewport location\nview_state = pdk.ViewState(latitude=37.7749295, longitude=-95.4194155, zoom=2, bearing=0, pitch=30)\n\n\n# Render\nr = pdk.Deck(layers=[layer], initial_view_state=view_state, \n             tooltip={\"text\": \"TotalPM25: {TotalPM25}\"})\nr.to_html(\"h3_cluster_layer.html\")\n```\n\n![png](/blog/2022-12-15-tutorial/output_world_map.png)",
    "title": "Tutorial: Accessing the source-receptor matrices from AWS",
    "author": "Xiao Ran",
    "authorURL": "https://github.com/xiaor2",
    "": "",
    "id": "Tutorial: Accessing the source-receptor matrices from AWS",
    "date": "2022-12-15T06:00:00.000Z",
    "seconds": 1671084000
  },
  {
    "path": "2019/04/20/sr.html",
    "content": "\nAir pollution source-receptor matrices give relationships between emissions at source locations and concentrations at receptor locations.\nThis tutorial demonstrates how to use source-receptor matrices to estimate health impacts of air pollution emissions.\n\n<!--truncate-->\n\n## Introduction\n\nSource-receptor (SR) matrices can allow users to get results similar to those that would be produced by running an air quality model simulation, but without having to actually run an air quality model simulation. In this tutorial, we will learn how to work with the SR matrices described in these two papers:\n\n* Jinhyok Heo, Peter J. Adams, H. Gao (2017) Public Health Costs Accounting of Inorganic PM<sub>2.5</sub> Pollution in Metropolitan Areas of the United States Using a Risk-Based Source-Receptor Model, <i>Environment International</i>, 106, 119â€“126. ([link](https://barney.ce.cmu.edu/~jinhyok/apsca/))\n\n* Andrew L. Goodkind, Christopher W. Tessum, Jay S. Coggins, Jason D. Hill, Julian D. Marshall (2019) Fine-scale damage estimates of particulate matter air pollution reveal opportunities for location-specific mitigation of emissions. <i>Proceedings of the National Academy of Sciences</i>. ([link](https://www.pnas.org/content/early/2019/04/02/1816102116.short))\n\nWe will refer to the SR matrix from the first paper as APSCA, and the one from the second paper as ISRM.\n\nAlthough SR matrices are typically easier to use than full air quality models, they are often made up of files that can be hundreds of gigabytes in size, and it can be complicated to get estimates of emissions into the correct format to use with the SR matrix.\nWe have developed some tools to get around these limitations: the website https://inmap.run hosts the SR matrices described in the two papers above and provides functionality for taking emissions in [shapefile](https://doc.arcgis.com/en/arcgis-online/reference/shapefiles.htm) format, running them through an SR matrix, and returning the result as a shapefile.\nAdditionally, the [`inmap cloud`](https://inmap.run/docs/cmd/inmap_cloud/) command-line tool allows users to interact with the https://inmap.run website.\n\nBecause not all users may be comfortable using command-line tools or shapefiles, we will demonstrate here how to use the [GeoPandas](http://geopandas.org/) library in the [Python](https://www.python.org/) scripting and programming language to interact with https://inmap.run, which will hopefully provide an additional level of convenience.\n\nIf you prefer, a working [Jupyter notebook](https://jupyter.org/) version of this tutorial is available [here](https://github.com/spatialmodel/inmap/blob/master/website/static/blog/2019-04-20-sr/sr_example.ipynb).\n\n## Set up environment\n\nThe code below is some boilerplate to make this work with either Python version 2 or 3.\n\n\n```python\nfrom __future__ import (absolute_import, division,\n                        print_function, unicode_literals)\nfrom builtins import *\n```\n\n## Prepare emissions\n\nFor this example, we are going to estimate the air pollution-related health impacts of electricity generation in the United States.\nTo do this we will start with emissions data from the US EPA's [National Emissions Inventory](https://www.epa.gov/air-emissions-modeling/emissions-modeling-platforms) for [year 2016](https://www.epa.gov/air-emissions-modeling/2016-alpha-platform).\n\nThe tools at https://inmap.run require input data containing:\n* information on the location of the emissions source (required, in the form of either a point, line, or polygon geometry with a [spatial reference](https://en.wikipedia.org/wiki/Spatial_reference_system) specified),\n* amounts of emissions (optional, allowed emission types are VOC, NOx, NH3, SOx, and PM2_5; units must be either short tons per year, kilograms per year, or micrograms per second), and\n* (smoke) stack parameters relevant to plume rise, which is how high up the emissions go immediately after they are released (optional; allowed parameters are \"height\", \"diam\", \"temp\", and \"velocity\" in units of m, m, K, and m/s, respectively).\n\nThe NEI data we are downloading includes, among other things, all of the information above. More information about the file format is available [here](https://www.cmascenter.org/smoke/documentation/4.5/html/ch08s02s08.html#sect_input_ptinv_ff10).\n\nAlthough there are a number of ways to process spatial data using Python, for this exercise we will use the [GeoPandas](http://geopandas.org/) library. Instructions for installing GeoPandas are [here](http://geopandas.org/install.html).\n\nThe code below downloads the emissions data from the EPA and converts it into a GeoPandas dataframe. Keep in mind that if you have a different type of emissions data that you want to use, you may want to use a different method for importing it.\nIn general, the tools we work with here are for estimating the concentration and health impacts of pollutant emissions, not for estimating the emissions themselves.\n\n\n```python\n# Note: This step can take a while to run.\n\nfrom io import BytesIO, TextIOWrapper\nfrom zipfile import ZipFile\nimport urllib.request\nimport csv\nfrom shapely.geometry import Point\nimport geopandas as gpd\n\n# Download file from EPA website.\nurl = urllib.request.urlopen(\"ftp://newftp.epa.gov/air/emismod/2016/alpha/2016fd/emissions/2016fd_inputs_point.zip\")\n\nVOC, NOx, NH3, SOx, PM2_5 = [], [], [], [], []\nheight, diam, temp, velocity = [], [], [],  []\ncoords = []\n\ndef add_record(row):\n    \"\"\" Process one row of the emissions file \"\"\"\n    pol = row[12] # The pollutant is in the 13th column of the CSV file\n                  # (In Python, the first column is called column 0.)\n    emis = row[13] # We are only extracting annual total emissions here.\n                   # If monthly emissions are reported, we'll miss them.\n                   # Emissions are short tons/year.\n    if emis == '': return\n    if pol in ['VOC', 'VOC_INV', 'XYL', 'TOL', 'TERP', 'PAR', 'OLE', 'NVOL', 'MEOH',\n               'ISOP', 'IOLE', 'FORM', 'ETOH', 'ETHA', 'ETH', 'ALD2', 'ALDX', 'CB05_ALD2',\n               'CB05_ALDX', 'CB05_BENZENE', 'CB05_ETH', 'CB05_ETHA', 'CB05_ETOH',\n               'CB05_FORM', 'CB05_IOLE', 'CB05_ISOP', 'CB05_MEOH', 'CB05_OLE', 'CB05_PAR',\n               'CB05_TERP', 'CB05_TOL', 'CB05_XYL', 'ETHANOL', 'NHTOG', 'NMOG', 'VOC_INV']:\n        VOC.append(float(emis))\n        NOx.append(0)\n        NH3.append(0)\n        SOx.append(0)\n        PM2_5.append(0)\n    elif pol in ['PM25-PRI', 'PM2_5', 'DIESEL-PM25', 'PAL', 'PCA', 'PCL', 'PEC', 'PFE', 'PK',\n                'PMG', 'PMN', 'PMOTHR', 'PNH4', 'PNO3', 'POC', 'PSI', 'PSO4', 'PTI']:\n        VOC.append(0)\n        NOx.append(0)\n        NH3.append(0)\n        SOx.append(0)\n        PM2_5.append(float(emis))\n    elif pol in ['NOX', 'HONO', 'NO', 'NO2']:\n        VOC.append(0)\n        NOx.append(float(emis))\n        NH3.append(0)\n        SOx.append(0)\n        PM2_5.append(0)\n    elif pol == 'NH3':\n        VOC.append(0)\n        NOx.append(0)\n        NH3.append(float(emis))\n        SOx.append(0)\n        PM2_5.append(0)\n    elif pol == 'SO2':\n        VOC.append(0)\n        NOx.append(0)\n        NH3.append(0)\n        SOx.append(float(emis))\n        PM2_5.append(0)\n    else: return\n\n    h = row[17]\n    height.append(float(h) * 0.3048) if h != '' else height.append(0)\n\n    d = row[18]\n    diam.append(float(d) * 0.3048) if d != '' else diam.append(0)\n\n    t = row[19]\n    temp.append((float(t) - 32) * 5.0/9.0 + 273.15) if t != '' else temp.append(0)\n\n    v = row[21]\n    velocity.append(float(v) * 0.3048) if v != '' else velocity.append(0)\n\n    coords.append(Point(float(row[23]), float(row[24])))\n\nwith ZipFile(BytesIO(url.read())) as zf:\n    for contained_file in zf.namelist():\n        if \"egu\" in contained_file: # Only process files with electricity generating unit (EGU) emissions.\n            for row in csv.reader(TextIOWrapper(zf.open(contained_file, 'r'), newline='')):\n                if (len(row) == 0) or (len(row[0]) == 0) or (row[0][0] == '#'): continue\n                add_record(row)\n\nemis = gpd.GeoDataFrame({\n    \"VOC\": VOC, \"NOx\": NOx, \"NH3\": NH3, \"SOx\": SOx, \"PM2_5\": PM2_5,\n    \"height\": height, \"diam\": diam, \"temp\": temp, \"velocity\": velocity,\n}, geometry=coords, crs={'init': 'epsg:4269'})\n```\n\nNow, let's inspect our emissions to ensure they look resonable.\n\n\n```python\n# First, we print the first several rows of the dataframe:\nemis.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VOC</th>\n      <th>NOx</th>\n      <th>NH3</th>\n      <th>SOx</th>\n      <th>PM2_5</th>\n      <th>height</th>\n      <th>diam</th>\n      <th>temp</th>\n      <th>velocity</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.573831 32.381659)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.573825 32.381989)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.573851 32.380321)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.573842 32.380647)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48.768</td>\n      <td>5.7912</td>\n      <td>348.15</td>\n      <td>15.60576</td>\n      <td>POINT (-86.573842 32.380647)</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\n# Now, let's look at the sums of emissions for all power plants (in short tons/year).\nemis.sum(axis=0)[[\"VOC\", \"NOx\", \"NH3\", \"SOx\", \"PM2_5\"]]\n```\n\n\n\n\n    VOC      3.345280e+04\n    NOx      1.314463e+06\n    NH3      2.501248e+04\n    SOx      1.571217e+06\n    PM2_5    1.408227e+05\n    dtype: float64\n\n\n\n\n```python\n# Finally, lets make some maps of the emissions.\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npols = [\"SOx\", \"NOx\", \"PM2_5\", \"VOC\", \"NH3\"]\npol_names = [\"SO$_2$\", \"NO$_x$\", \"PM$_{2.5}$\", \"VOC\", \"NH$_3$\"]\n\nfig, axes = plt.subplots(figsize=(7, 3), nrows=2, ncols=3, sharex=True, sharey=True)\nplt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.1, hspace=0.1)\n\ni = 0\nfor x in axes:\n    for ax in x:\n        if i < len(pols):\n            emis.plot(ax=ax, markersize=emis[pols[i]]**0.5 / 5)\n            ax.set_title(pol_names[i])\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.axis('off')\n        i = i+1\nplt.show()\n```\n\n\n![png](/blog/2019-04-20-sr/output_7_0.png)\n\n\nFig. 1: US year-2016 electricity generators. Areas of dots are proportionate to rate of emissions of each pollutant.\n\nThese maps could be improved by adding politcal boundaries, etc. We will leave that as an exercise for the reader.\n\n\nAlternatively to the steps above, if you already have a shapefile of the correct format saved locally, you could read it in using:\n\n```python\nimport geopandas as gpd\nemis = gpd.read_file(\"/path/to/file.shp\")\n```\n\n## Use SR matrices to estimate concentrations and health impacts\n\nOnce we have our emissions in GeoPandas format, we are ready to run them through our SR matrices.\nTo do this, we will use the `run_sr` function in the `sr_util.py` script that we have created for this purpose. You can view `sr_util.py` [here](https://github.com/spatialmodel/inmap/blob/master/website/static/blog/2019-04-20-sr/sr_util.py), and if you want to run the code here you will need to download the file into the directory you are working in.\n\nThe `run_sr` function takes several arguments, which we will describe here.\n\n* `emis`: A geopandas dataframe of emissions, like the one we've prepared here.\n\n* `model`: Which SR matrix to use. Currently the ISRM (Goodkind et al. paper above) and APSCA (Heo et al. paper above) models are available. The options for this argument are:\n    * `isrm`: The InMAP SR matrix\n    * `apsca_q0`: The APSCA SR matrix, annual average\n    * `apsca_q1`: The APSCA SR matrix, Jan-Mar season\n    * `apsca_q2`: The APSCA SR matrix, Apr-Jun season\n    * `apsca_q3`: The APSCA SR matrix, Jul-Sep season\n    * `apsca_q4`: The APSCA SR matrix, Oct-Dec season\n\n* `emis_units`: The units that the emissions are in. Allowed values: `tons/year`, `kg/year`, `ug/s`, and `Î¼g/s`. We will use tons/year, because those are the units our data are in.\n\n* `output_variables`: The information we want the model to output, input as a dictionary in the form {\"variable_name\": \"formula\"}. Refer [here](https://inmap.run/docs/results/) for more information regarding formulas. The native model variables available in the SR matrices for use in output formulas are:\n    * `PrimaryPM25`: Calculated primary PM<sub>2.5</sub> concentration (Î¼g/mÂ³)\n    * `pNH4`: Calculated particulate NH<sub>4</sub> concentration (Î¼g/mÂ³)\n    * `pSO4`: Calculated particulate SO<sub>4</sub> concentration (Î¼g/mÂ³)\n    * `pNO3`: Calculated particulate NO</sub>3</sub> concentration (Î¼g/mÂ³)\n    * `SOA`: Calculated secondary organic aerosol concentration (Î¼g/mÂ³)\n    * `Asian`: Year 2010 Asian Population (people/grid cell)\n    * `Black`: Year 2010 Black Population (people/grid cell)\n    * `Latino`: Year 2010 Latino Population (people/grid cell)\n    * `Native`: Year 2010 Native Population (people/grid cell)\n    * `TotalPop`: Year 2010 total Population (people/grid cell)\n    * `WhiteNoLat`: Year 2010 White non-Latino Population (people/grid cell)\n    * `MortalityRate`: Year 2005 baseline overall population mortality rate (deaths per year per 100,000 people)\n    * `Baseline NH3`: Baseline NH3 Concentration (Î¼g/mÂ³)\n    * `Baseline NOx`: Baseline NOx Concentration (Î¼g/mÂ³)\n    * `Baseline SOA`: Baseline SOA Concentration (Î¼g/mÂ³)\n    * `Baseline SOx`: Baseline SOx Concentration (Î¼g/mÂ³)\n    * `Baseline TotalPM25`: Baseline TotalPM25 Concentration (Î¼g/mÂ³)\n    * `Baseline VOC`: Baseline VOC Concentration (Î¼g/mÂ³)\n    * `Baseline pNH4`: Baseline pNH4 Concentration (Î¼g/mÂ³)\n    * `Baseline pNO3`: Baseline pNO3 Concentration (Î¼g/mÂ³)\n    * `Baseline pSO4`: Baseline pSO4 Concentration (Î¼g/mÂ³)\n    * `Asian`: Year 2010 Asian Population (people/grid cell)\n    * `Black`: Year 2010 Black Population (people/grid cell)\n    * `Latino`: Year 2010 Latino Population (people/grid cell)\n    * `Native`: Year 2010 Native Population (people/grid cell)\n    * `TotalPop`: Year 2010 total Population (people/grid cell)\n    * `WhiteNoLat`: Year 2010 White non-Latino Population (people/grid cell)\n    * `UAvg`: Average East-West wind speed (m/s)\n    * `VAvg`: Average North-South wind speed (m/s)\n    * `WAvg`: Average up-down wind speed (m/s)\n    * `UDeviation`: Average deviation from East-West velocity (m/s)\n    * `VDeviation`: Average deviation from North-South velocity (m/s)\n    * `AOrgPartitioning`: Organic particle partitioning (-)\n    * `SPartitioning`: Sulfur particle partitioning (-)\n    * `NOPartitioning`: Nitrate particle partitioning (-)\n    * `NHPartitioning`: Ammonium particle partitioning (-)\n    * `SO2oxidation`: SO2 oxidation to SO4 by HO and H2O2 (1/s)\n    * `ParticleWetDep`: Particle wet deposition (1/s)\n    * `SO2WetDep`: SO2 wet deposition (1/s)\n    * `OtherGasWetDep`: Wet deposition: other gases (1/s)\n    * `ParticleDryDep`: Particle dry deposition (m/s)\n    * `NH3DryDep`: Ammonia dry deposition (m/s)\n    * `SO2DryDep`: SO2 dry deposition (m/s)\n    * `VOCDryDep`: VOC dry deposition (m/s)\n    * `NOxDryDep`: NOx dry deposition (m/s)\n    * `Kzz`: Grid center vertical diffusivity after applying convective fraction (mÂ²/s)\n    * `Kxxyy`: Grid center horizontal diffusivity (mÂ²/s)\n    * `M2u`: ACM2 upward mixing (Pleim 2007)  (1/s)\n    * `M2d`: ACM2 downward mixing (Pleim 2007) (1/s)\n    * `Dx`: Cell x length (m)\n    * `Dy`: Cell y length (m)\n    * `Dz`: Cell z length (m)\n    * `Volume`: Cell volume (mÂ³)\n    * `Temperature`: Average temperature (K)\n    * `WindSpeed`: RMS wind speed (m/s)\n    * `WindSpeedInverse`: RMS wind speed inverse (s/m)\n    * `WindSpeedMinusThird`: RMS wind speed^(-1/3)\n    * `WindSpeedMinusOnePointFour`: RMS wind speed^(-1.4)\n    * `S1`: Stability parameter (?)\n    * `SClass`: Stability class (0=Unstable; 1=Stable)\n    * `N`: N grid cell edge (m)\n    * `S`: S grid cell edge (m)\n    * `E`: E grid cell edge (m)\n    * `W`: W grid cell edge (m)\n\nYou can probably see that there are an infinite number of output variables that could be calculated. For this example, we will output three variables:\n\n1. `TotalPM25 = PrimaryPM25 + pNH4 + pSO4 + pNO3 + SOA`: In this equation, we are summing up all the different types of PM<sub>2.5</sub> that the model calculates to get total PM<sub>2.5</sub>.\n\n2. `deathsK = (exp(log(1.06)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate / 100000 * 1.025229357798165` In this equation, we are using the total PM<sub>2.5</sub> value we calculated above in a [Cox proportional hazards](https://en.wikipedia.org/wiki/Proportional_hazards_model) equation, along with information on population counts (`TotalPop`) and baseline mortality rates (`MortalityRate / 100000`) to calculate the number of deaths.\n    * 1.0465819687408728 is the ratio between year-2016 population (what we want) and year-2010 population (what the model has).\n    * 1.025229357798165 is the ratio between year-2016 mortality rate (what we want) and year-2005 mortality rate (what the model has).\n    * The value 1.06 represents an assumption that overall mortality rate increases by 6% for every 10 Î¼g/mÂ³ increase in PM<sub>2.5</sub> concentration, which is taken from [this](https://www.healtheffects.org/publication/extended-follow-and-spatial-analysis-american-cancer-society-study-linking-particulate) paper.\n    * The variable name, `deathsK`, comes from the fact that we're calculating deaths and that the 1.06 value comes from a report authored by Krewski et al.\n\n3. `deathsL = (exp(log(1.14)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate * 1.025229357798165 / 100000`: This is the same equation as the previous one, except we assume a 14% increase in morality rate for every 10 Î¼g/mÂ³ increase in PM<sub>2.5</sub> concentration, as [reported by LePeule et al](https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.1104660).\n\n\n```python\n# This step might take a while.\n\nfrom sr_util import run_sr # This allows us to use the 'run_sr' function\n                           # in the 'sr_util.py' file in this same directory.\n\noutput_variables = {\n    'TotalPM25':'PrimaryPM25 + pNH4 + pSO4 + pNO3 + SOA',\n    'deathsK':'(exp(log(1.06)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate / 100000 * 1.025229357798165',\n    'deathsL':'(exp(log(1.14)/10 * TotalPM25) - 1) * TotalPop * 1.0465819687408728 * MortalityRate / 100000 * 1.025229357798165',\n}\n\nresultsISRM = run_sr(emis, model=\"isrm\", emis_units=\"tons/year\", output_variables=output_variables)\n```\n\n    Finished (626 seconds)                               \n\n\n\n```python\nresultsAPSCA = run_sr(emis, model=\"apsca_q0\", emis_units=\"tons/year\", output_variables=output_variables)\n```\n\n    Finished (371 seconds)                          \n\n\n## Summarize results\n\nNow that we have our results, the first thing we can do is sum up the number of deaths we are calculating:\n\n\n```python\nimport pandas as pd\n\ndeaths = pd.DataFrame.from_dict({\n    \"Model\": [\"ISRM\", \"APSCA\"],\n    \"Krewski Deaths\": [resultsISRM.deathsK.sum(), resultsAPSCA.deathsK.sum()],\n    \"LePeule Deaths\": [resultsISRM.deathsL.sum(), resultsAPSCA.deathsL.sum()],\n})\n\ndeaths\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Krewski Deaths</th>\n      <th>LePeule Deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISRM</td>\n      <td>6928.959583</td>\n      <td>15623.924632</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>APSCA</td>\n      <td>6035.354385</td>\n      <td>13598.336851</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nWe're calculating somewhere between 6,000 and 16,000 deaths every year caused by air pollution emissions from electricity generators.\n\nWe can also estimate equivalent economic damages using a metric called Value of a Statistical Life, which we will take to be $9 million.\n\n\n```python\nvsl = 9.0e6\n\npd.DataFrame.from_dict({\n    \"Model\": [\"ISRM\", \"APSCA\"],\n    \"Krewski Damages\": deaths[\"Krewski Deaths\"] * vsl,\n    \"LePeule Damages\": deaths[\"LePeule Deaths\"] * vsl,\n})\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Krewski Damages</th>\n      <th>LePeule Damages</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISRM</td>\n      <td>6.236064e+10</td>\n      <td>1.406153e+11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>APSCA</td>\n      <td>5.431819e+10</td>\n      <td>1.223850e+11</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nSo the health damages from power plants are equivalent to between 50 and 140 billion dollars per year. By using multiple SR matrices and multiple esitimates of the relationship between concentrations and mortality rate, we're able to estimate the uncertainty in our results.\n\nThe final thing we'll do here is to make maps of our concentration results:\n\n\n```python\nimport numpy as np\n\nq = 0.995 # We are going to truncate our results at the 99.5th percentile\n          # to make the maps easier to interpret.\ncut = resultsISRM.TotalPM25.append(resultsAPSCA.TotalPM25, ignore_index=True).quantile(q)\n\n\nfig, axes = plt.subplots(figsize=(7, 2.5), nrows=1, ncols=2, sharex=True, sharey=True)\nplt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n\n# Create the color bar.\nim1 = axes[0].imshow(np.random.random((10,10)), vmin=0, cmap=\"GnBu\", vmax=cut)\nfig.subplots_adjust(right=0.85)\ncbar_ax1 = fig.add_axes([0.86, 0.05, 0.025, 0.9])\nc1 = fig.colorbar(im1, cax=cbar_ax1)\nc1.ax.set_ylabel('PM$_{2.5}$ concentration (Î¼g m$^{-3}$)')\naxes[0].clear()\n\nresultsISRM.plot(ax=axes[0], vmin=0, vmax=cut, cmap=\"GnBu\", column=\"TotalPM25\")\nresultsAPSCA.plot(ax=axes[1], vmin=0, vmax=cut, cmap=\"GnBu\", column=\"TotalPM25\")\n\naxes[0].axis('off')\naxes[1].axis('off')\n\naxes[0].set_title(\"ISRM\")\naxes[1].set_title(\"APSCA\")\n\nplt.show()\n```\n\n\n![png](/blog/2019-04-20-sr/output_16_0.png)\n\n\nFig. 2: PM<sub>2.5</sub> concentrations caused by electricity generation in the US.\n\nAs above, the maps would be better if political boundaries were added for reference, but we will leave that as homework, as there are other tutorials out there that describe how to do that.\n\nTo save out the results as a shapefile, use the following command:\n\n```python\nresultsISRM.to_file(\"output.shp\")\n```\n\nShapefiles can be opened in a GIS tool like [QGIS](https://qgis.org/) for further postprocessing if desired.\n\n\n## Conclusion\n\nHopefully this tutorial has given you the information you need to do your own air pollution analyses using SR matrices. If not, you can browse the documentation at https://inmap.run or contact the InMAP users group at https://groups.google.com/forum/#!forum/inmap-users.\n",
    "title": "Working with source-receptor matrices using https://inmap.run and GeoPandas in Python",
    "author": "Chris Tessum",
    "authorURL": "https://github.com/ctessum",
    "id": "Working with source-receptor matrices using https://inmap.run and GeoPandas in Python",
    "date": "2019-04-20T06:00:00.000Z",
    "seconds": 1555740000
  },
  {
    "path": "2019/03/04/tutorial.html",
    "content": "\nThis blog post contains a step-by-step example of how to create an emissions\nscenario and use the InMAP model to estimate the resulting health impacts.\n\n<!--truncate-->\n\n## 1. Introduction\n\nThe Volkswagen emissions defeat device was exposed in September 2015, when the Volkswagen Group of America (VW) admitted to violating the Clean Air Act (CAA) by installing emissions control system \"defeat devices\" designed to circumvent emissions tests<sup>1</sup>. The United States Environmental Protection Agency had found that the affected VW vehicles output NO<sub>x</sub> emissions at rates up to 40 times more than the EPA standard during on-road emissions testing. A couple of researchers have published the estimated exposure and health impact of the excess pollution emissions caused by the defeat devices. Several different chemical transport models were used in their studies, such as the GEOS-Chem adjoint model (Barrett et al., 2015)<sup>2</sup> and the MIROC-ESM-CHEM model (Holland et al., 2015)<sup>3</sup>. In this blog post, we will repeat the excersize using InMAP.\n\nThe Intervention Model for Air Pollution (InMAP)<sup>4</sup> is a reduced-complexity air quality model designed to provide estimates of air pollution health impacts resulting caused by emissions of PM<sub>2.5</sub> and its precursors. To run InMAP, users need a shapefile or set of shapefiles containing locations of changes in annual total emissions of VOCs, SO<sub>x</sub>, NO<sub>x</sub>, NH<sub>3</sub>, and primary fine particulate matter (PM<sub>2.5</sub>).\n\nThis tutorial will walk through the entire process of running the model step by step, taking the VW excess emissions as an example. We will start by explaining how to prepare the inputs with QGIS. Then we will display the process of installing the InMAP and running the model with our input file. Finally, the results will be compared with past studies on VW excess emissions in the USA.\n\n## 2. Preparing Inputs on GIS\n\n### 2.1 Getting Emissions Data\n\nGenerally, the required user-inputs for running InMAP model are a set of shapefiles containing the annual total emissions of various pollutants. In the VW case, we will use excess NO<sub>x</sub> emissions to estimate the exposures of PM<sub>2.5</sub> and the resulting health effects. To create the feasible input files for running the model, we need the emission rate of VW vehicles in each year we interested and an on-road emission locations shapefile provided by NEI (National Emissions Inventory). For the former, we can use the estimated total excess NO<sub>x</sub> emission in the study by Barrett et al. (2015) as follows:\n\n<p style=\"text-align: center; font-weight: bold\">\nTable. 1 Annual excess VW light duty diesel vehicle NO<sub>x</sub> emissions in kilotonnes (million kg) from 2008 to 2015\n</p>\n\n<table style=\"margin: 0px auto;\">\n  <tr>\n    <th>Year</th>\n    <th>2008</th>\n    <th>2009</th>\n    <th>2010</th>\n    <th>2011</th>\n    <th>2012</th>\n    <th>2013</th>\n    <th>2014</th>\n    <th>2015</th>\n  </tr>\n  <tr>\n    <td>NO<sub>x</sub> emission rate (ktonnes/year)</td>\n    <td>0.2</td>\n    <td>1</td>\n    <td>1.2</td>\n    <td>2.8</td>\n    <td>4.7</td>\n    <td>6.7</td>\n    <td>9.2</td>\n    <td>10.1</td>\n  </tr>\n</table>\n\n\nFor the on-road total emission shapefile, it can be download from here: [https://my.pcloud.com/publink/show?code=kZe8uh7ZYU6MWRSeaABsCJ6v2AzpLRHHOx7X](https://my.pcloud.com/publink/show?code=kZe8uh7ZYU6MWRSeaABsCJ6v2AzpLRHHOx7X). The shapefile can be open and edit on a bunch of GIS software. For individual users, QGIS is one of the most generally used GIS application since it is free and includes most of commonly used functions. It is compatible with Windows, Mac and Linux system. This tutorial will demonstrate all the operations need to be done on a GIS platform, including the data preparing and post-process.\n\n### 2.2 Renormalize Data\n\nNext, we need to spatially allocate the VW NO<sub>x</sub> emission rates to the on-road emissions locations. To do this, open the on-road emissions shapefile mentioned before. What we are going to do is to renormalize the existing emissions so that their sum will equal to the emissions sum from the paper. The formula is given by:\n\n<p style=\"text-align: center; font-style: italic;\">\nnew\\_emissions = existing\\_emissions / sum(existing\\_emissions) \\* emissions\\_total\\_from\\_paper\n</p>\n\nUsually, this can be done by using the filed calculator tool in the menu bar as showed below.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image001.jpg\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 1. Creating new emission field using field calculator\n</p>\n\n\nHowever, since there are too much point features in this case (1168664 points). The calculating would be extremely slow when GIS processing large shapefile so that it is hardly to get the result using this method without a program crash. Fortunately, there is another trick to do the renormalization instead of using the field calculator directly. We will need to export the shapefile data as spatialite database. The data processing in the format of spatialite database is much faster than it is in shapefile, it will still take minutes to calculate due to the large size of data though. To convert the format of the original data, you can right click on the &quot;onroad&quot; shp data in the table of contents window (aka. layer tree) as shown in Figure 2.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image002.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 2. Exporting layer data as SpatiaLite database\n</p>\n\nIn the popped-up window, choose the location you want to save your spatialite data. The on-road data contains varieties of pollutant&#39;s concentration. Since many of them are ones will not be used, it would be better to delete some of them. In this study, only the emission of NO<sub>x</sub> is required so that other fields will be deleted. You can do this in the &quot;Save vector layer asâ€¦&quot; window by selecting fields to be exported.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image003.jpg\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 3. Saving layer options\n</p>\n\nAlternatively, you can also delete redundant fields in the properties window of the layer file. As shown in Figure 4, in the source filed bar, click &quot;Toggle editing mode&quot; button first. Then choose the fields you intend to delete and click &quot;Delete field&quot; button to remove it.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image004.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 4. Removing fields in properties window\n</p>\n\nAfter the onroad emission data is converted, we may now use the calculator to create the renormalized emission in the opened &quot;.sqlite&quot; file. What should also be mentioned here is that do not use the field calculator with the attribute table open, which would also significantly decrease the running speed. Otherwise, the QGIS will have a great chance to crash. Recall that the unit of the data from the paper is ktonnes/year, which is not one of the input unit values that InMAP supports. So it is important to convert to the appropriate unit when calculating. You would need to repeat the last step, the standardizing, for eight times to get the feasible input data of each year between 2008-2015.\n\nDon&#39;t forget that the appropriate format of InMAP model input is shapefile. Therefore, after creating the spatialite data, it is important to convert them back to shapefile format. The final version of data for InMAP model input would be eight standardized shapefiles. In this study, the data used is official published dataset without incorrect data or &quot;NULL&quot; data. If you intend to run the InMAP model with your own data in the future, some data cleaning may be needed.\n\n\n\n## 3. Getting Started with InMAP\n\nYou can install InMAP by following the instructions [here](/docs/install).\n\n## 4. Modeling\n\n### 4.1 Configuration\n\nThe first step of setting up an InMAP model simulation is to configure the emission scenario. Emissions files should be in shapefile format where the attribute columns correspond to the names of emitted pollutants. The acceptable pollutant names are VOC, NO<sub>x</sub>, NH3, SOx, and PM2\\_5. The model can handle multiple input files, for example, the shapefiles of different elevation. In this case, we only concern the ground level emission.\n\nThen make a copy of the configuration file template and you are going to edit it to meet our scenario condition. The interface of the configuration file should be like below (Figure 5). As seen in the interface, there are a series of parameters you can determine. First, set the `evaldata` environment variable to the directory you downloaded the evaluation data to, or replace all instances of `${evaldata}` in the configuration file with the path to that directory. You must also ensure that the directory `OutputFile` is to go in exists. Second, choose an emission unit of the input. It should be consistent with the unit in your emission shapefile. Next, set the path of the output file and the log file. Finally, you can look at the output variables (Figure 6) to see which are the output you want to generate. Details about the built-in and calculated variables can be found [here](/docs/results).\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image005.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 5. Model Configuration (1)\n</p>\n\n### 4.2 Running InMAP\n\nNow you are all set to run the model, using the command below:\n\n```\ninmapX.X.X run steady -s --config=/path/to/configfile.toml\n```\n\nwhere `inmapX.X.X` is the name of the executable binary file you have downloaded or compiled on your system. Refer [here](/docs/run_config) for more information.\n\nInMAP can run with either a [static](/docs/variable_grid/#static-grid-resolution-algorithm) or [dynamically changing](/docs/variable_grid/#dynamic-grid-resolution-algorithm) grid. Depending on the simulation being run and the configuration settings being used, one or the other grid type may work best; refer [here](/docs/variable_grid) for further discussion. For this tutorial, we will use the static grid as specified by the `-s` flag above.\n\nYou should model the health impact year by year for total 8 times to get the output from 2008-2015.\n\n## 5. Results and post-processing\n\n### 5.1 Post-processing\n\nThe raw output would be like figure 7 below, taking the 2008 data as an example.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image007.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 7. An InMAP output shapefile\n</p>\n\nOpen the attribute table to see all the desired variables we have. We will focus on the &quot;TotalPM25&quot; field.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image008.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 8. Attribute table of the 2008 output\n</p>\n\nThe features are not symbolized correctly yet. We cannot tell any useful information from the raw output map. Now we are going to make the output more visual. In the menu bar, go to Vector -\\&gt; Geometry tools -\\&gt; Centroids. Setting the input layer to your output shapefile and run the tool. After this is accomplished, there will be a new layer in the table of contents, which is a point layer that could be symbolled as a heatmap. Open the properties window of the new layer, choose heatmap as its symbol, set other options as below.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image009.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 9. Options for heatmap\n</p>\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image010.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 10. Heatmap for total PM<sub>2.5</sub>\n</p>\n\nNow the heatmap has been created successfully. But it is still hard to tell the areas with high exposure level belong to which part of U.S. So you need a U.S. states boundary map which you can download here:\n\n[https://www.arcgis.com/home/item.html?id=f7f805eb65eb4ab787a0a3e1116ca7e5](https://www.arcgis.com/home/item.html?id=f7f805eb65eb4ab787a0a3e1116ca7e5). Open it and move this layer above the heatmap layer. In the properties window, set the fill color to transparent.\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image011.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 11. Symbolizing the boundary of the state\n</p>\n\nYour map now should look like this:\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image012.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 12. Improved output map\n</p>\n\nPut the outputs from 2008 to 2015 together to see the variation:\n\n<p style=\"text-align: center;\">\n<img src=\"/blog/2019-03-04-tutorial/image013.png\" width=\"80%\"/>\n</p>\n\n<p style=\"text-align: center; font-weight: bold\">\nFigure 13. Total PM<sub>2.5</sub> from 2008 to 2015\n</p>\n\n### 5.2 Compare with Existing Studies\n\nThere has been some previous research on the health impacts of the excess emissions caused by the VW defeat devices. Barrett et al. (2015)<sup>2</sup> and Holland et al. (2015)<sup>3</sup> published estimates of additional emissions of NO<sub>x</sub> and subsequent health damages due to the using of defeat devices committed by Volkswagen Group in the USA. And Oldenkamp et al. (2016)<sup>5</sup> further considered the damages due to ozone formation in addition to PM<sub>2.5</sub>. We can compare our results with theirs. First, we  export each output data to the format of CSV. The data processing is much faster in excel than it is in QGIS. We are interested in the comparison of the total early death from 2008 to 2015 between our model and theirs. So we need to calculate the sum of &quot;TotalPopD&quot; field for each year then sum them together. Table 2 shows the comparison of our result and one from other researches.\n\n<p style=\"text-align: center; font-weight: bold\">\nTable 2. The comparison of early deaths among studies. (\\*95% confidence interval in brackets)\n</p>\n\n<table style=\"margin: 0px auto;\">\n  <tr>\n    <th>Studies</th>\n    <th>Total emissions (ktonnes)</th>\n    <th>Early deaths (incidences)</th>\n  </tr>\n  <tr>\n    <td>This study</td>\n    <td>36.7 (Data from Barrett el al.)</td>\n    <td>85.2</td>\n  </tr>\n  <tr>\n    <td>Barrett et al. (2015)</td>\n    <td>36.7 (12.3-61.2)*</td>\n    <td>59 (9.7-150)*</td>\n  </tr>\n  <tr>\n    <td>Holland et al. (2015)</td>\n    <td>45.1</td>\n    <td>46.1</td>\n  </tr>\n  <tr>\n    <td>Rik et al. (2016)</td>\n    <td>33.8</td>\n    <td>59.2</td>\n  </tr>\n</table>\n\n### 5.3 Conclusion\n\nOur analysis provides an estimate of the public health consequences caused by the additional emissions from Volkswagen defeat devices. The result shows an increase in PM<sub>2.5</sub> over time and a spatial distribution that the higher exposure concentration appears at the Eastern and Western coast, Midwest, and Texas. According to the output, there would be average 85 deaths in the U.S.A from 2008 to 2015 due to the extra emission, which is similar to the findings of the previous studies.\n\n## References\n\n<sup>1</sup>Wikipedia contributors. (2018, December 6). Volkswagen emissions scandal. In _Wikipedia, The Free Encyclopedia_. Retrieved December 13, 2018, from [https://en.wikipedia.org/w/index.php?title=Volkswagen\\_emissions\\_scandal&amp;oldid=872379047](https://en.wikipedia.org/w/index.php?title=Volkswagen_emissions_scandal&amp;oldid=872379047)\n\n<sup>2</sup>Barrett, S. R., Speth, R. L., Eastham, S. D., Dedoussi, I. C., Ashok, A., Malina, R., &amp; Keith, D. W. (2015). Impact of the Volkswagen emissions control defeat device on US public health. _Environmental Research Letters_, 10(11), 114005.\n\n<sup>3</sup>Holland, S. P., Mansur, E. T., Muller, N. Z., &amp; Yates, A. J. (2016). Response to Comment on &quot;Damages and expected deaths due to excess NO x emissions from 2009â€“2015 Volkswagen diesel vehicles&quot;. _Environmental science &amp; technology_, 50(7), 4137-4138.\n\n<sup>4</sup>Tessum, C. W., Hill, J. D., &amp; Marshall, J. D. (2017). InMAP: A model for air pollution interventions. _PloS one_, 12(4), e0176131.\n\n<sup>5</sup>Oldenkamp, R., van Zelm, R., & Huijbregts, M. A. (2016). Valuing the human health damage caused by the fraud of Volkswagen. _Environmental Pollution_, 212, 121-127.\n",
    "title": "Tutorial: Estimating health impacts of the Volkswagen emissions scandal",
    "author": "Xinyu Zhang",
    "authorURL": "https://www.linkedin.com/in/xinyu-ryan-zhang/",
    "id": "Tutorial: Estimating health impacts of the Volkswagen emissions scandal",
    "date": "2019-03-04T06:00:00.000Z",
    "seconds": 1551679200
  }
];
